# ğŸŒ World Discovery Engine (WDE) â€” Architecture

`scripts/ARCHITECTURE.md`

---

## 0. Purpose & Scope

The **World Discovery Engine (WDE)** is a **multi-modal AI pipeline** developed for the **OpenAI â†’ Z Challenge**.
Its mission: surface **archaeologically significant candidates** (Anthropogenic Dark Earths (ADEs), earthworks, geoglyphs, settlements) using **open geospatial datasets**, **computer vision**, **causal inference**, and **simulation frameworks**.

WDE outputs **candidate site dossiers** with:

* ğŸ“¡ Multi-sensor overlays (Sentinel, Landsat, SAR, LiDAR, DEMs)
* ğŸŒ± Soil & vegetation fingerprints (ADE indicators, MapBiomas floristic maps)
* ğŸ“œ Historical & archival references (OCR-processed maps, diaries, site DBs)
* ğŸ”— Causal plausibility graphs (Partial Ancestral Graphs, Bayesian GNNs)
* ğŸ§© Refutation & counterfactual tests (SSIM, uncertainty simulations)

---

## 1. Data Ecosystem

**Core Open Datasets:**

* Sentinel-1 (SAR), Sentinel-2 (optical)
* Landsat Collection 2 (historical optical)
* NICFI Planet mosaics (4.7 m tropical imagery)
* SRTM, Copernicus DEM (30mâ€“90m global elevation)
* GEDI LiDAR (forest structure), OpenTopography LiDAR
* MODIS climate & vegetation (NDVI/EVI, land cover)
* MapBiomas land cover (Amazon, Latin America)
* HydroSHEDS hydrography (rivers, floodplains)

**Supplementary Sources:**

* Historical maps, diaries, and archives (OCR + geoparsing)
* Core sampling databases (NOAA Paleoclimatology, PANGAEA, Neotoma, ICDP, IODP)
* Soil databases (ISRIC WoSIS, SISLAC, RADAMBRASIL)

**Multi-Modal Fusion:**
User-uploaded docs, images, or overlays can be integrated (georeferenced maps, local soil cores, photos).

---

## 2. Discovery Funnel (Pipeline Stages)

### Step 1: **Tiling & Ingestion**

* Grid AOI into \~5 km tiles.
* Ingest Sentinel, DEM, soil, vegetation, hydro, historical overlays.
* Normalize into multi-band â€œoverlay stack.â€

### Step 2: **Coarse Scan**

* CV: edges, Hough transforms, textures
* DEM analysis: hillshades, local relief models
* VLM captioning (CLIP, PaliGemma, Prithvi-EO)
* Output: anomaly heatmap + ranked tiles

### Step 3: **Mid-Scale Evaluation**

* LiDAR/DEM canopy removal
* NDVI/EVI seasonal persistence checks
* Hydro-geomorph plausibility (terraces, ridges near water)
* Historical concordance with OCRâ€™d maps & diaries
* Overlay concordance with user uploads

### Step 4: **Verification**

* Multi-proof requirement: â‰¥2 independent evidence sources
* ADE fingerprints: dry-season NDVI spike, floristic anomalies, phosphorus-rich soils
* Bayesian GNN for uncertainty
* PAG causal graph validation
* Counterfactual SSIM test

### Step 5: **Candidate Reports**

Each candidate dossier includes:

1. Bounding box map
2. DEM/LiDAR panels
3. NDVI/EVI plots
4. SAR overlays
5. Historical snippet
6. PAG causal graph
7. Uncertainty histograms
8. SSIM map
9. ADE fingerprint summary
10. Refutation & confidence narrative

---

## 3. Repository Architecture

Repository follows modular scientific pipeline design:

```
world-discovery-engine/
â”œâ”€â”€ world_engine/              # Core Python package
â”‚   â”œâ”€â”€ ingest.py              # Step 1
â”‚   â”œâ”€â”€ detect.py              # Step 2
â”‚   â”œâ”€â”€ evaluate.py            # Step 3
â”‚   â”œâ”€â”€ verify.py              # Step 4
â”‚   â”œâ”€â”€ report.py              # Step 5
â”‚   â”œâ”€â”€ models/                # GNNs, anomaly detectors
â”‚   â”œâ”€â”€ utils/                 # geospatial, image, OCR, logging
â”‚   â””â”€â”€ cli.py                 # Typer CLI (ingest, scan, eval, verify, report)
â”‚
â”œâ”€â”€ configs/                   # YAML configs (AOI, datasets, thresholds)
â”œâ”€â”€ data/                      # managed by DVC/Kaggle (raw, interim, outputs)
â”œâ”€â”€ notebooks/                 # Kaggle-ready pipeline notebook
â”œâ”€â”€ scripts/                   # utility bash/python scripts
â”œâ”€â”€ tests/                     # unit & integration tests
â”œâ”€â”€ docs/                      # architecture, datasets, ethics
â”œâ”€â”€ .github/workflows/         # CI/CD (lint, tests, pipeline check)
â”œâ”€â”€ Dockerfile                 # reproducible runtime
â”œâ”€â”€ requirements.txt           # pinned deps
â””â”€â”€ README.md
```

Supports: modularity, reproducibility, Kaggle execution, and ethics compliance.

---

## 4. Ethics & Governance

* CARE Principles (Collective Benefit, Authority, Responsibility, Ethics)
* FPIC (Free, Prior, Informed Consent) integration
* Masking coordinates in sensitive areas
* Compliance with national laws (e.g., IPHAN in Brazil)
* Community collaboration: feedback loops, metadata contribution
* ETHICS.md in repo documents policies

---

## 5. Execution Backbone

* **Reproducibility:** Hydra configs + DVC + Kaggle datasets
* **CI/CD:** Lint, unit tests, integration (dummy AOI), ethics checks
* **Artifacts:** run manifests, per-site reports, logs
* **Scaling:** Tile-based parallelism, cloud-ready (COGs, Dask/Spark)

---

## 6. Success Criteria

* Archaeological impact: ADE proxies & new site leads
* Multi-proof validation: â‰¥2 modalities per candidate
* Reproducibility: deterministic configs & logs
* Ethics: sovereignty-aware, no data colonialism
* Presentation: dossiers as polished â€œcase filesâ€

---

âœ… This **scripts/ARCHITECTURE.md** is now a **canonical in-repo architecture guide**, aligning code structure with the discovery funnel, dataset registry, ethics overlays, and Kaggle challenge requirements.

---
