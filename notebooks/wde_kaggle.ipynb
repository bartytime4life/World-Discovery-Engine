{
â€œcellsâ€: [
{
â€œcell_typeâ€: â€œmarkdownâ€,
â€œmetadataâ€: {},
â€œsourceâ€: [
â€œ# ğŸŒ World Discovery Engine (WDE) â€” Kaggle Notebook (Ready-to-Upload)\nâ€,
â€œ\nâ€,
â€œMinimal, self-contained scaffold that mirrors the WDE pipeline stages and produces real artifacts on Kaggle without external dependencies:\nâ€,
â€œ\nâ€,
â€œStages: data â†’ preprocess â†’ detect â†’ verify (demo) â†’ dossier â†’ manifests\nâ€,
â€œ\nâ€,
â€œWhat you get\nâ€,
â€œ- Deterministic seeds + environment printout\nâ€,
â€œ- Synthetic AOI tiling + demo raster tile with a planted anomaly\nâ€,
â€œ- Coarse anomaly detection (Canny edges) + scoring\nâ€,
â€œ- Candidate artifacts (JSON + PNG) and a simple dossier per candidate\nâ€,
â€œ- Final run manifest & short file tree recap\nâ€,
â€œ\nâ€,
â€œ> Replace the demo data generation with real fetchers and models as you develop. This notebook intentionally avoids private packages so it will run on fresh Kaggle kernels out of the box.â€
]
},
{
â€œcell_typeâ€: â€œcodeâ€,
â€œexecution_countâ€: null,
â€œmetadataâ€: {},
â€œoutputsâ€: [],
â€œsourceâ€: [
â€œ# â€” Environment & Reproducibility â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“\nâ€,
â€œimport os, sys, json, math, random, pathlib, time, datetime as dt\nâ€,
â€œfrom typing import Dict, Any\nâ€,
â€œ\nâ€,
â€œprint(â€˜Python:â€™, sys.version)\nâ€,
â€œprint(â€˜CWD:â€™, pathlib.Path.cwd())\nâ€,
â€œ\nâ€,
â€œ# Set standard roots (overridable via env)\nâ€,
â€œos.environ.setdefault(â€˜WDE_DATA_ROOTâ€™, â€˜./dataâ€™)\nâ€,
â€œos.environ.setdefault(â€˜WDE_ARTIFACTS_ROOTâ€™, â€˜./artifactsâ€™)\nâ€,
â€œDATA_ROOT = pathlib.Path(os.environ[â€˜WDE_DATA_ROOTâ€™]).resolve()\nâ€,
â€œART_ROOT = pathlib.Path(os.environ[â€˜WDE_ARTIFACTS_ROOTâ€™]).resolve()\nâ€,
â€œprint(â€˜WDE_DATA_ROOT =â€™, DATA_ROOT)\nâ€,
â€œprint(â€˜WDE_ARTIFACTS_ROOT =â€™, ART_ROOT)\nâ€,
â€œ\nâ€,
â€œ# Deterministic seeds (for numpy/random and torch when available)\nâ€,
â€œSEED = int(os.environ.get(â€˜WDE_SEEDâ€™, â€˜2025â€™))\nâ€,
â€œrandom.seed(SEED)\nâ€,
â€œtry:\nâ€,
â€œ    import numpy as np\nâ€,
â€œexcept Exception as e:\nâ€,
â€œ    raise RuntimeError(â€˜NumPy is required in Kaggle runtime.â€™) from e\nâ€,
â€œnp.random.seed(SEED)\nâ€,
â€œ\nâ€,
â€œtry:\nâ€,
â€œ    import torch\nâ€,
â€œ    torch.manual_seed(SEED)\nâ€,
â€œ    TORCH_OK = True\nâ€,
â€œ    USE_GPU = torch.cuda.is_available()\nâ€,
â€œexcept Exception:\nâ€,
â€œ    TORCH_OK = False\nâ€,
â€œ    USE_GPU = False\nâ€,
â€œprint(â€˜Torch available:â€™, TORCH_OK, â€˜| GPU:â€™, USE_GPU)\nâ€,
â€œ\nâ€,
â€œ# CV/Plot deps: try import; if missing on Kaggle, these are usually present.\nâ€,
â€œtry:\nâ€,
â€œ    import cv2\nâ€,
â€œexcept Exception:\nâ€,
â€œ    cv2 = None\nâ€,
â€œtry:\nâ€,
â€œ    import matplotlib.pyplot as plt\nâ€,
â€œ    from matplotlib import cm\nâ€,
â€œexcept Exception:\nâ€,
â€œ    plt = None\nâ€,
â€œ\nâ€,
â€œRUN_TS = dt.datetime.utcnow().replace(microsecond=0).isoformat() + â€˜Zâ€™\nâ€,
â€œprint(â€˜Run timestamp (UTC):â€™, RUN_TS)â€
]
},
{
â€œcell_typeâ€: â€œcodeâ€,
â€œexecution_countâ€: null,
â€œmetadataâ€: {},
â€œoutputsâ€: [],
â€œsourceâ€: [
â€œ# â€” Small IO helpers (self-contained) â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“\nâ€,
â€œdef ensure_dir(p: os.PathLike) -> pathlib.Path:\nâ€,
â€œ    p = pathlib.Path(p)\nâ€,
â€œ    p.mkdir(parents=True, exist_ok=True)\nâ€,
â€œ    return p\nâ€,
â€œ\nâ€,
â€œdef write_json(path: os.PathLike, obj: Dict[str, Any]):\nâ€,
â€œ    path = pathlib.Path(path)\nâ€,
â€œ    ensure_dir(path.parent)\nâ€,
â€œ    with path.open(â€˜wâ€™, encoding=â€˜utf-8â€™) as f:\nâ€,
â€œ        json.dump(obj, f, indent=2, ensure_ascii=False)\nâ€,
â€œ    return path\nâ€,
â€œ\nâ€,
â€œdef save_png(path: os.PathLike, img_arr):\nâ€,
â€œ    path = pathlib.Path(path)\nâ€,
â€œ    ensure_dir(path.parent)\nâ€,
â€œ    if cv2 is None:\nâ€,
â€œ        raise RuntimeError(â€˜OpenCV not available: cannot save PNG in this minimal demo.â€™)\nâ€,
â€œ    # If RGB in range 0..255, write directly\nâ€,
â€œ    if img_arr.ndim == 3 and img_arr.shape[2] == 3:\nâ€,
â€œ        # OpenCV expects BGR; convert if input is RGB\nâ€,
â€œ        bgr = img_arr[â€¦, ::-1]\nâ€,
â€œ        cv2.imwrite(str(path), bgr)\nâ€,
â€œ    else:\nâ€,
â€œ        cv2.imwrite(str(path), img_arr)\nâ€,
â€œ    return path\nâ€,
â€œ\nâ€,
â€œdef limited_tree(root: os.PathLike, max_files: int = 64):\nâ€,
â€œ    root = pathlib.Path(root)\nâ€,
â€œ    out = []\nâ€,
â€œ    count = 0\nâ€,
â€œ    for dirpath, , filenames in os.walk(root):\nâ€,
â€œ        dp = pathlib.Path(dirpath)\nâ€,
â€œ        for fn in sorted(filenames):\nâ€,
â€œ            out.append(str((dp / fn).relative_to(root)))\nâ€,
â€œ            count += 1\nâ€,
â€œ            if count >= max_files:\nâ€,
â€œ                out.append(â€™â€¦ (truncated)â€™)\nâ€,
â€œ                return out\nâ€,
â€œ    return outâ€
]
},
{
â€œcell_typeâ€: â€œcodeâ€,
â€œexecution_countâ€: null,
â€œmetadataâ€: {},
â€œoutputsâ€: [],
â€œsourceâ€: [
â€œ# â€” Config (edit me) â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€“â€“\nâ€,
â€œCONFIG = {\nâ€,
â€œ    "run": {\nâ€,
â€œ        "seed": SEED,\nâ€,
â€œ        "timestamp_utc": RUN_TS,\nâ€,
â€œ    },\nâ€,
â€œ    "aoi": {\nâ€,
â€œ        # (min_lat, min_lon, max_lat, max_lon) â€” tiny box for demo\nâ€,
â€œ        "bbox": (-3.500, -60.500, -3.450, -60.450)\nâ€,
â€œ    },\nâ€,
â€œ    "tiling": {\nâ€,
â€œ        "tile_size_deg": 0.05,   # ~5km in latitude; demo will produce at most one tile here\nâ€,
â€œ        "img_size": 256          # demo raster size per tile (pixels)\nâ€,
â€œ    },\nâ€,
â€œ    "detect": {\nâ€,
â€œ        "canny_low": 50,\nâ€,
â€œ        "canny_high": 150,\nâ€,
â€œ        "min_edge_score": 2000   # threshold to flag a candidate\nâ€,
â€œ    },\nâ€,
â€œ    "paths": {\nâ€,
â€œ        "data_raw": str(DATA_ROOT / â€˜rawâ€™),\nâ€,
â€œ        "data_processed": str(DATA_ROOT / â€˜processedâ€™),\nâ€,
â€œ        "candidates": str(ART_ROOT / â€˜candidatesâ€™),\nâ€,
â€œ        "dossiers": str(ART_ROOT / â€˜dossiersâ€™)\nâ€,
â€œ    }\nâ€,
â€œ}\nâ€,
â€œ\nâ€,
â€œprint(json.dumps(CONFIG, indent=2))\nâ€,
â€œ\nâ€,
â€œ# Ensure directories\nâ€,
â€œensure_dir(CONFIG[â€˜pathsâ€™][â€˜data_rawâ€™])\nâ€,
â€œensure_dir(CONFIG[â€˜pathsâ€™][â€˜data_processedâ€™])\nâ€,
â€œensure_dir(CONFIG[â€˜pathsâ€™][â€˜candidatesâ€™])\nâ€,
â€œensure_dir(CONFIG[â€˜pathsâ€™][â€˜dossiersâ€™])\nâ€,
â€œprint(â€˜Verified minimal directory structure.â€™)â€
]
},
{
â€œcell_typeâ€: â€œmarkdownâ€,
â€œmetadataâ€: {},
â€œsourceâ€: [
â€œ## 1) Data (demo) â†’ Synthetic AOI Tile\nâ€,
â€œFor a minimal, offline-safe run, we generate a single RGB tile with an injected circular anomaly. Replace this cell with your real data fetchers (Sentinel/Landsat/SRTM/NICFI).â€
]
},
{
â€œcell_typeâ€: â€œcodeâ€,
â€œexecution_countâ€: null,
â€œmetadataâ€: {},
â€œoutputsâ€: [],
â€œsourceâ€: [
â€œimg_size = CONFIG[â€˜tilingâ€™][â€˜img_sizeâ€™]\nâ€,
â€œ\nâ€,
â€œ# Synthetic RGB background\nâ€,
â€œrgb = np.zeros((img_size, img_size, 3), dtype=np.uint8)\nâ€,
â€œrgb[â€¦, 1] = 35  # a faint greenish baseline to mimic vegetation tint\nâ€,
â€œ\nâ€,
â€œ# Inject a bright circular anomaly at the center (white disk)\nâ€,
â€œcx = cy = img_size // 2\nâ€,
â€œrr = img_size // 8\nâ€,
â€œyy, xx = np.ogrid[:img_size, :img_size]\nâ€,
â€œmask = (xx - cx)**2 + (yy - cy)2 <= rr2\nâ€,
â€œrgb[mask] = [255, 255, 255]\nâ€,
â€œ\nâ€,
â€œ# Save demo tile\nâ€,
â€œtile_png = pathlib.Path(CONFIG[â€˜pathsâ€™][â€˜data_processedâ€™]) / â€˜tile_000_rgb.pngâ€™\nâ€,
â€œsave_png(tile_png, rgb)\nâ€,
â€œ\nâ€,
â€œ# Create a minimal fetch manifest\nâ€,
â€œfetch_manifest = {\nâ€,
â€œ    "created": RUN_TS,\nâ€,
â€œ    "seed": SEED,\nâ€,
â€œ    "aoi_bbox": CONFIG[â€˜aoiâ€™][â€˜bboxâ€™],\nâ€,
â€œ    "tiles": [{"id": 0, "path": str(tile_png), "shape": list(rgb.shape)}]\nâ€,
â€œ}\nâ€,
â€œwrite_json(pathlib.Path(CONFIG[â€˜pathsâ€™][â€˜data_rawâ€™]) / â€˜fetch_manifest.jsonâ€™, fetch_manifest)\nâ€,
â€œprint(â€˜Wrote synthetic tile and fetch_manifest.jsonâ€™)â€
]
},
{
â€œcell_typeâ€: â€œmarkdownâ€,
â€œmetadataâ€: {},
â€œsourceâ€: [
â€œ## 2) Preprocess â†’ (placeholder)\nâ€,
â€œIn a real run, you would reproject, resample, normalize, and stack multi-sensor layers (optical / SAR / DEM). This demo just writes a placeholder preprocess manifest.â€
]
},
{
â€œcell_typeâ€: â€œcodeâ€,
â€œexecution_countâ€: null,
â€œmetadataâ€: {},
â€œoutputsâ€: [],
â€œsourceâ€: [
â€œpreprocess_manifest = {\nâ€,
â€œ    "created": RUN_TS,\nâ€,
â€œ    "layers": [\nâ€,
â€œ        {"name": "optical_rgb", "path": str(tile_png), "normalized": False}\nâ€,
â€œ    ]\nâ€,
â€œ}\nâ€,
â€œwrite_json(pathlib.Path(CONFIG[â€˜pathsâ€™][â€˜data_processedâ€™]) / â€˜preprocess_manifest.jsonâ€™, preprocess_manifest)\nâ€,
â€œprint(â€˜Wrote preprocess_manifest.jsonâ€™)â€
]
},
{
â€œcell_typeâ€: â€œmarkdownâ€,
â€œmetadataâ€: {},
â€œsourceâ€: [
â€œ## 3) Detect â†’ Canny Edges + Score\nâ€,
â€œWe use a basic edge-density score as a stand-in for a fast coarse anomaly detector. If the score exceeds a threshold, we produce a candidate with a preview PNG and JSON entry.\nâ€,
â€œ\nâ€,
â€œ> Replace with your CV/VLM/DEM/VL model inference (e.g., CLIP caption similarity, hillshade features, RF/UNet, etc.).â€
]
},
{
â€œcell_typeâ€: â€œcodeâ€,
â€œexecution_countâ€: null,
â€œmetadataâ€: {},
â€œoutputsâ€: [],
â€œsourceâ€: [
â€œif cv2 is None:\nâ€,
â€œ    raise RuntimeError(â€˜OpenCV not available; cannot run demo detector.â€™)\nâ€,
â€œif plt is None:\nâ€,
â€œ    raise RuntimeError(â€˜matplotlib not available; cannot render previews.â€™)\nâ€,
â€œ\nâ€,
â€œ# Load back the synthetic tile\nâ€,
â€œimg_bgr = cv2.imread(str(tile_png))\nâ€,
â€œif img_bgr is None:\nâ€,
â€œ    raise RuntimeError(fâ€™Failed to read {tile_png}â€™)\nâ€,
â€œimg_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\nâ€,
â€œ\nâ€,
â€œ# Canny\nâ€,
â€œlow, high = CONFIG[â€˜detectâ€™][â€˜canny_lowâ€™], CONFIG[â€˜detectâ€™][â€˜canny_highâ€™]\nâ€,
â€œedges = cv2.Canny(img_gray, low, high)\nâ€,
â€œedge_score = int(edges.sum() // 255)  # count of edge pixels\nâ€,
â€œprint(â€˜Edge score:â€™, edge_score)\nâ€,
â€œ\nâ€,
â€œ# Candidate decision\nâ€,
â€œcand_list = []\nâ€,
â€œif edge_score >= CONFIG[â€˜detectâ€™][â€˜min_edge_scoreâ€™]:\nâ€,
â€œ    cand_id = 0\nâ€,
â€œ    cand_png = pathlib.Path(CONFIG[â€˜pathsâ€™][â€˜candidatesâ€™]) / fâ€™candidate{cand_id:03d}.pngâ€™\nâ€,
â€œ    cand_json = pathlib.Path(CONFIG[â€˜pathsâ€™][â€˜candidatesâ€™]) / fâ€™candidate_{cand_id:03d}.jsonâ€™\nâ€,
â€œ\nâ€,
â€œ    # Make a side-by-side preview\nâ€,
â€œ    fig, ax = plt.subplots(1, 2, figsize=(8, 4), dpi=120)\nâ€,
â€œ    ax[0].set_title(â€˜optical (demo)â€™)\nâ€,
â€œ    ax[0].imshow(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))\nâ€,
â€œ    ax[0].axis(â€˜offâ€™)\nâ€,
â€œ    ax[1].set_title(fâ€™edges (score={edge_score})â€™)\nâ€,
â€œ    ax[1].imshow(edges, cmap=â€˜grayâ€™)\nâ€,
â€œ    ax[1].axis(â€˜offâ€™)\nâ€,
â€œ    fig.tight_layout()\nâ€,
â€œ    fig.canvas.draw()\nâ€,
â€œ    # Save PNG via matplotlib savefig\nâ€,
â€œ    ensure_dir(cand_png.parent)\nâ€,
â€œ    fig.savefig(str(cand_png), bbox_inches=â€˜tightâ€™)\nâ€,
â€œ    plt.close(fig)\nâ€,
â€œ\nâ€,
â€œ    # Save candidate JSON\nâ€,
â€œ    cand_rec = {\nâ€,
â€œ        "id": cand_id,\nâ€,
â€œ        "score": edge_score,\nâ€,
â€œ        "threshold": CONFIG[â€˜detectâ€™][â€˜min_edge_scoreâ€™],\nâ€,
â€œ        "preview": str(cand_png),\nâ€,
â€œ        "source_tile": str(tile_png),\nâ€,
â€œ        "created": RUN_TS\nâ€,
â€œ    }\nâ€,
â€œ    write_json(cand_json, cand_rec)\nâ€,
â€œ    cand_list.append(cand_rec)\nâ€,
â€œelse:\nâ€,
â€œ    print(â€˜No candidates: score below threshold.â€™)\nâ€,
â€œ\nâ€,
â€œ# Write global candidates list\nâ€,
â€œcandidates_manifest = {\nâ€,
â€œ    "created": RUN_TS,\nâ€,
â€œ    "seed": SEED,\nâ€,
â€œ    "detector": "canny_edge_density",\nâ€,
â€œ    "params": {"low": low, "high": high, "min_edge_score": CONFIG[â€˜detectâ€™][â€˜min_edge_scoreâ€™]},\nâ€,
â€œ    "candidates": cand_list,\nâ€,
â€œ}\nâ€,
â€œwrite_json(pathlib.Path(CONFIG[â€˜pathsâ€™][â€˜candidatesâ€™]) / â€˜candidates.jsonâ€™, candidates_manifest)\nâ€,
â€œprint(fâ€™Wrote candidates.json with {len(cand_list)} entr(ies).â€™)â€
]
},
{
â€œcell_typeâ€: â€œmarkdownâ€,
â€œmetadataâ€: {},
â€œsourceâ€: [
â€œ## 4) Verify (demo) â†’ Simple Gate\nâ€,
â€œFor the minimal demo we treat the detectorâ€™s threshold as the entire verification step. In a real system, this stage should combine â‰¥2 modalities (e.g., DEM microrelief + vegetation time-series, or SAR + historical text) and produce calibrated uncertainty.\nâ€,
â€œ\nâ€,
â€œWe still emit a verification manifest to wire the stage, making it easy to swap in your real logic later.â€
]
},
{
â€œcell_typeâ€: â€œcodeâ€,
â€œexecution_countâ€: null,
â€œmetadataâ€: {},
â€œoutputsâ€: [],
â€œsourceâ€: [
â€œverified = []\nâ€,
â€œfor c in cand_list:\nâ€,
â€œ    # Demo: accept as-verified if the score exceeded threshold\nâ€,
â€œ    c2 = dict(c)\nâ€,
â€œ    c2["verified"] = True\nâ€,
â€œ    c2["uncertainty_demo"] = 0.25  # placeholder\nâ€,
â€œ    verified.append(c2)\nâ€,
â€œ\nâ€,
â€œverify_manifest = {\nâ€,
â€œ    "created": RUN_TS,\nâ€,
â€œ    "rule": "score>=min_edge_score",\nâ€,
â€œ    "verified": verified,\nâ€,
â€œ}\nâ€,
â€œwrite_json(pathlib.Path(CONFIG[â€˜pathsâ€™][â€˜candidatesâ€™]) / â€˜verify_manifest.jsonâ€™, verify_manifest)\nâ€,
â€œprint(â€˜Wrote verify_manifest.jsonâ€™)â€
]
},
{
â€œcell_typeâ€: â€œmarkdownâ€,
â€œmetadataâ€: {},
â€œsourceâ€: [
â€œ## 5) Dossier â†’ per-candidate bundle\nâ€,
â€œCreate a simple dossier (.md + .png) for each verified candidate. In the real pipeline this includes maps, overlays, time-series plots, uncertainty panels, and an ethics note/sovereignty banner where applicable.â€
]
},
{
â€œcell_typeâ€: â€œcodeâ€,
â€œexecution_countâ€: null,
â€œmetadataâ€: {},
â€œoutputsâ€: [],
â€œsourceâ€: [
â€œdossiers = []\nâ€,
â€œfor c in verified:\nâ€,
â€œ    did = c[â€˜idâ€™]\nâ€,
â€œ    md_path = pathlib.Path(CONFIG[â€˜pathsâ€™][â€˜dossiersâ€™]) / fâ€™dossier_{did:03d}.mdâ€™\nâ€,
â€œ    png_src = pathlib.Path(c[â€˜previewâ€™])\nâ€,
â€œ    # For the demo we re-use the preview image as the primary dossier figure\nâ€,
â€œ    record = {\nâ€,
â€œ        "id": did,\nâ€,
â€œ        "figure": str(png_src),\nâ€,
â€œ        "summary": {\nâ€,
â€œ            "score": c[â€˜scoreâ€™],\nâ€,
â€œ            "uncertainty_demo": c[â€˜uncertainty_demoâ€™],\nâ€,
â€œ            "source_tile": c[â€˜source_tileâ€™]\nâ€,
â€œ        }\nâ€,
â€œ    }\nâ€,
â€œ    md = []\nâ€,
â€œ    md.append(f"# Dossier â€” Candidate {did:03d}\n")\nâ€,
â€œ    md.append(f"- Created: {RUN_TS}\n")\nâ€,
â€œ    md.append(f"- Source tile: {c['source_tile']}\n")\nâ€,
â€œ    md.append(f"- Detector score: {c[â€˜scoreâ€™]} (min={CONFIG[â€˜detectâ€™][â€˜min_edge_scoreâ€™]})\n")\nâ€,
â€œ    md.append(f"- Uncertainty (demo): {c[â€˜uncertainty_demoâ€™]}\n")\nâ€,
â€œ    md.append(f"\n

\n")\nâ€,
â€œ    md.append("\n> NOTE: This is a minimal scaffold dossier. Replace with real maps, DEM hillshades, SAR overlays, NDVI time-series, and sovereignty notices as appropriate.\n")\nâ€,
â€œ    ensure_dir(md_path.parent)\nâ€,
â€œ    md_path.write_text("".join(md), encoding=â€˜utf-8â€™)\nâ€,
â€œ    dossiers.append({"id": did, "path": str(md_path)})\nâ€,
â€œ\nâ€,
â€œdossiers_manifest = {\nâ€,
â€œ    "created": RUN_TS,\nâ€,
â€œ    "count": len(dossiers),\nâ€,
â€œ    "items": dossiers,\nâ€,
â€œ}\nâ€,
â€œwrite_json(pathlib.Path(CONFIG[â€˜pathsâ€™][â€˜dossiersâ€™]) / â€˜dossiers_manifest.jsonâ€™, dossiers_manifest)\nâ€,
â€œprint(f"Wrote dossiers_manifest.json with {len(dossiers)} entr(ies).")â€
]
},
{
â€œcell_typeâ€: â€œmarkdownâ€,
â€œmetadataâ€: {},
â€œsourceâ€: [
â€œ## 6) Final Recap â†’ Manifests & File Tree\nâ€,
â€œWe summarize run metadata and print a limited file tree so you can quickly confirm artifacts exist. Use the Kaggle sidebar or the output browser to download your results.â€
]
},
{
â€œcell_typeâ€: â€œcodeâ€,
â€œexecution_countâ€: null,
â€œmetadataâ€: {},
â€œoutputsâ€: [],
â€œsourceâ€: [
â€œfinal_manifest = {\nâ€,
â€œ    "run": CONFIG[â€˜runâ€™],\nâ€,
â€œ    "aoi": CONFIG[â€˜aoiâ€™],\nâ€,
â€œ    "tiling": CONFIG[â€˜tilingâ€™],\nâ€,
â€œ    "detect": CONFIG[â€˜detectâ€™],\nâ€,
â€œ    "paths": CONFIG[â€˜pathsâ€™],\nâ€,
â€œ    "artifacts": {\nâ€,
â€œ        "candidates_json": str(pathlib.Path(CONFIG[â€˜pathsâ€™][â€˜candidatesâ€™]) / â€˜candidates.jsonâ€™),\nâ€,
â€œ        "verify_manifest": str(pathlib.Path(CONFIG[â€˜pathsâ€™][â€˜candidatesâ€™]) / â€˜verify_manifest.jsonâ€™),\nâ€,
â€œ        "dossiers_manifest": str(pathlib.Path(CONFIG[â€˜pathsâ€™][â€˜dossiersâ€™]) / â€˜dossiers_manifest.jsonâ€™)\nâ€,
â€œ    }\nâ€,
â€œ}\nâ€,
â€œwrite_json(ART_ROOT / â€˜run_manifest.jsonâ€™, final_manifest)\nâ€,
â€œprint(â€˜Saved artifacts/run_manifest.jsonâ€™)\nâ€,
â€œ\nâ€,
â€œprint(â€™\n# artifacts/â€™)\nâ€,
â€œfor p in limited_tree(ART_ROOT, max_files=200):\nâ€,
â€œ    print(â€™ -â€™, p)\nâ€,
â€œ\nâ€,
â€œprint(â€™\n# data/â€™)\nâ€,
â€œfor p in limited_tree(DATA_ROOT, max_files=200):\nâ€,
â€œ    print(â€™ -â€™, p)\nâ€,
â€œ\nâ€,
â€œprint(â€™\nDone.â€™)â€
]
},
{
â€œcell_typeâ€: â€œmarkdownâ€,
â€œmetadataâ€: {},
â€œsourceâ€: [
â€œ## Next Steps (Swap in your real pipeline)\nâ€,
â€œ1. Data Fetchers â†’ Replace the synthetic tile with real data loaders (Sentinel/Landsat/SRTM/NICFI). Keep small AOIs for Kaggle limits.\nâ€,
â€œ2. Preprocess â†’ Tile/reproject/normalize stacks; compute DEM hillshades & local relief; clip to AOI.\nâ€,
â€œ3. Detect â†’ Add your CV/VLM/DEM detection: edges+Hough, CLIP similarity, UNet segmentation, random forest on environmental layers, etc.\nâ€,
â€œ4. Verify â†’ Enforce multi-proof rules (e.g., DEM microrelief + vegetation seasonal anomaly), causal plausibility graph, and calibrated uncertainty.\nâ€,
â€œ5. Dossier â†’ Render maps/overlays/plots (NDVI time-series, SAR backscatter, DEM), add sovereignty notes (CARE) when applicable.\nâ€,
â€œ6. Configs â†’ Keep all knobs in configs/*.yaml; pin seeds and dataset versions for reproducibility; wire to your CLI.\nâ€,
â€œ7. CI â†’ If running in your repo via Actions, run lint/tests/repro checks on each PR; for Kaggle, prefer pinned images + Save & Run All.â€
]
}
],
â€œmetadataâ€: {
â€œkernelspecâ€: {
â€œdisplay_nameâ€: â€œPython 3â€,
â€œlanguageâ€: â€œpythonâ€,
â€œnameâ€: â€œpython3â€
},
â€œlanguage_infoâ€: {
â€œnameâ€: â€œpythonâ€,
â€œversionâ€: â€œ3.12â€
}
},
â€œnbformatâ€: 4,
â€œnbformat_minorâ€: 5
}