{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŒ World Discovery Engine (WDE) â€” Kaggle Notebook (Ready-to-Upload)\n",
        "\n",
        "Minimal, self-contained scaffold that mirrors the WDE pipeline stages and produces real artifacts on Kaggle without external dependencies:\n",
        "\n",
        "Stages: data â†’ preprocess â†’ detect â†’ verify (demo) â†’ dossier â†’ manifests\n",
        "\n",
        "What you get\n",
        "- Deterministic seeds + environment printout\n",
        "- Synthetic AOI tiling + demo raster tile with a planted anomaly\n",
        "- Coarse anomaly detection (Canny edges) + scoring\n",
        "- Candidate artifacts (JSON + PNG) and a simple dossier per candidate\n",
        "- Final run manifest & short file tree recap\n",
        "\n",
        "> Replace the demo data generation with real fetchers and models as you develop. This notebook intentionally avoids private packages so it will run on fresh Kaggle kernels out of the box."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Environment & Reproducibility -----------------------------------------\n",
        "import os, sys, json, math, random, pathlib, time, datetime as dt\n",
        "from typing import Dict, Any\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('CWD:', pathlib.Path.cwd())\n",
        "\n",
        "# Set standard roots (overridable via env)\n",
        "os.environ.setdefault('WDE_DATA_ROOT', './data')\n",
        "os.environ.setdefault('WDE_ARTIFACTS_ROOT', './artifacts')\n",
        "DATA_ROOT = pathlib.Path(os.environ['WDE_DATA_ROOT']).resolve()\n",
        "ART_ROOT = pathlib.Path(os.environ['WDE_ARTIFACTS_ROOT']).resolve()\n",
        "print('WDE_DATA_ROOT =', DATA_ROOT)\n",
        "print('WDE_ARTIFACTS_ROOT =', ART_ROOT)\n",
        "\n",
        "# Deterministic seeds (for numpy/random and torch when available)\n",
        "SEED = int(os.environ.get('WDE_SEED', '2025'))\n",
        "random.seed(SEED)\n",
        "try:\n",
        "    import numpy as np\n",
        "except Exception as e:\n",
        "    raise RuntimeError('NumPy is required in Kaggle runtime.') from e\n",
        "np.random.seed(SEED)\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    torch.manual_seed(SEED)\n",
        "    TORCH_OK = True\n",
        "    USE_GPU = torch.cuda.is_available()\n",
        "except Exception:\n",
        "    TORCH_OK = False\n",
        "    USE_GPU = False\n",
        "print('Torch available:', TORCH_OK, '| GPU:', USE_GPU)\n",
        "\n",
        "# CV/Plot deps: try import; if missing on Kaggle, these are usually present.\n",
        "try:\n",
        "    import cv2\n",
        "except Exception:\n",
        "    cv2 = None\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    from matplotlib import cm\n",
        "except Exception:\n",
        "    plt = None\n",
        "\n",
        "RUN_TS = dt.datetime.utcnow().replace(microsecond=0).isoformat() + 'Z'\n",
        "print('Run timestamp (UTC):', RUN_TS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Small IO helpers (self-contained) --------------------------------------\n",
        "def ensure_dir(p: os.PathLike) -> pathlib.Path:\n",
        "    p = pathlib.Path(p)\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "    return p\n",
        "\n",
        "def write_json(path: os.PathLike, obj: Dict[str, Any]):\n",
        "    path = pathlib.Path(path)\n",
        "    ensure_dir(path.parent)\n",
        "    with path.open('w', encoding='utf-8') as f:\n",
        "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
        "    return path\n",
        "\n",
        "def save_png(path: os.PathLike, img_arr):\n",
        "    path = pathlib.Path(path)\n",
        "    ensure_dir(path.parent)\n",
        "    if cv2 is None:\n",
        "        raise RuntimeError('OpenCV not available: cannot save PNG in this minimal demo.')\n",
        "    # If RGB in range 0..255, write directly\n",
        "    if img_arr.ndim == 3 and img_arr.shape[2] == 3:\n",
        "        # OpenCV expects BGR; convert if input is RGB\n",
        "        bgr = img_arr[..., ::-1]\n",
        "        cv2.imwrite(str(path), bgr)\n",
        "    else:\n",
        "        cv2.imwrite(str(path), img_arr)\n",
        "    return path\n",
        "\n",
        "def limited_tree(root: os.PathLike, max_files: int = 64):\n",
        "    root = pathlib.Path(root)\n",
        "    out = []\n",
        "    count = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(root):\n",
        "        dp = pathlib.Path(dirpath)\n",
        "        for fn in sorted(filenames):\n",
        "            out.append(str((dp / fn).relative_to(root)))\n",
        "            count += 1\n",
        "            if count >= max_files:\n",
        "                out.append('â€¦ (truncated)')\n",
        "                return out\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Config (edit me) -------------------------------------------------------\n",
        "CONFIG = {\n",
        "    \"run\": {\n",
        "        \"seed\": SEED,\n",
        "        \"timestamp_utc\": RUN_TS\n",
        "    },\n",
        "    \"aoi\": {\n",
        "        # (min_lat, min_lon, max_lat, max_lon) â€” tiny box for demo\n",
        "        \"bbox\": (-3.500, -60.500, -3.450, -60.450)\n",
        "    },\n",
        "    \"tiling\": {\n",
        "        \"tile_size_deg\": 0.05,   # ~5km in latitude; demo will produce at most one tile here\n",
        "        \"img_size\": 256          # demo raster size per tile (pixels)\n",
        "    },\n",
        "    \"detect\": {\n",
        "        \"canny_low\": 50,\n",
        "        \"canny_high\": 150,\n",
        "        \"min_edge_score\": 2000   # threshold to flag a candidate\n",
        "    },\n",
        "    \"paths\": {\n",
        "        \"data_raw\": str(DATA_ROOT / 'raw'),\n",
        "        \"data_processed\": str(DATA_ROOT / 'processed'),\n",
        "        \"candidates\": str(ART_ROOT / 'candidates'),\n",
        "        \"dossiers\": str(ART_ROOT / 'dossiers')\n",
        "    }\n",
        "}\n",
        "\n",
        "print(json.dumps(CONFIG, indent=2))\n",
        "\n",
        "# Ensure directories\n",
        "ensure_dir(CONFIG['paths']['data_raw'])\n",
        "ensure_dir(CONFIG['paths']['data_processed'])\n",
        "ensure_dir(CONFIG['paths']['candidates'])\n",
        "ensure_dir(CONFIG['paths']['dossiers'])\n",
        "print('Verified minimal directory structure.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Data (demo) â†’ Synthetic AOI Tile\n",
        "For a minimal, offline-safe run, we generate a single RGB tile with an injected circular anomaly. Replace this cell with your real data fetchers (Sentinel/Landsat/SRTM/NICFI)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_size = CONFIG['tiling']['img_size']\n",
        "\n",
        "# Synthetic RGB background\n",
        "rgb = np.zeros((img_size, img_size, 3), dtype=np.uint8)\n",
        "rgb[..., 1] = 35  # a faint greenish baseline to mimic vegetation tint\n",
        "\n",
        "# Inject a bright circular anomaly at the center (white disk)\n",
        "cx = cy = img_size // 2\n",
        "rr = img_size // 8\n",
        "yy, xx = np.ogrid[:img_size, :img_size]\n",
        "mask = (xx - cx)**2 + (yy - cy)**2 <= rr**2\n",
        "rgb[mask] = [255, 255, 255]\n",
        "\n",
        "# Save demo tile\n",
        "tile_png = pathlib.Path(CONFIG['paths']['data_processed']) / 'tile_000_rgb.png'\n",
        "save_png(tile_png, rgb)\n",
        "\n",
        "# Create a minimal fetch manifest\n",
        "fetch_manifest = {\n",
        "    \"created\": RUN_TS,\n",
        "    \"seed\": SEED,\n",
        "    \"aoi_bbox\": CONFIG['aoi']['bbox'],\n",
        "    \"tiles\": [{\"id\": 0, \"path\": str(tile_png), \"shape\": list(rgb.shape)}]\n",
        "}\n",
        "write_json(pathlib.Path(CONFIG['paths']['data_raw']) / 'fetch_manifest.json', fetch_manifest)\n",
        "print('Wrote synthetic tile and fetch_manifest.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Preprocess â†’ (placeholder)\n",
        "In a real run, you would reproject, resample, normalize, and stack multi-sensor layers (optical / SAR / DEM). This demo just writes a placeholder preprocess manifest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocess_manifest = {\n",
        "    \"created\": RUN_TS,\n",
        "    \"layers\": [\n",
        "        {\"name\": \"optical_rgb\", \"path\": str(tile_png), \"normalized\": False}\n",
        "    ]\n",
        "}\n",
        "write_json(pathlib.Path(CONFIG['paths']['data_processed']) / 'preprocess_manifest.json', preprocess_manifest)\n",
        "print('Wrote preprocess_manifest.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Detect â†’ Canny Edges + Score\n",
        "We use a basic edge-density score as a stand-in for a fast coarse anomaly detector. If the score exceeds a threshold, we produce a candidate with a preview PNG and JSON entry.\n",
        "\n",
        "> Replace with your CV/VLM/DEM/VL model inference (e.g., CLIP caption similarity, hillshade features, RF/UNet, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if cv2 is None:\n",
        "    raise RuntimeError('OpenCV not available; cannot run demo detector.')\n",
        "if plt is None:\n",
        "    raise RuntimeError('matplotlib not available; cannot render previews.')\n",
        "\n",
        "# Load back the synthetic tile\n",
        "img_bgr = cv2.imread(str(tile_png))\n",
        "if img_bgr is None:\n",
        "    raise RuntimeError(f'Failed to read {tile_png}')\n",
        "img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Canny\n",
        "low, high = CONFIG['detect']['canny_low'], CONFIG['detect']['canny_high']\n",
        "edges = cv2.Canny(img_gray, low, high)\n",
        "edge_score = int(edges.sum() // 255)  # count of edge pixels\n",
        "print('Edge score:', edge_score)\n",
        "\n",
        "# Candidate decision\n",
        "cand_list = []\n",
        "if edge_score >= CONFIG['detect']['min_edge_score']:\n",
        "    cand_id = 0\n",
        "    cand_png = pathlib.Path(CONFIG['paths']['candidates']) / f'candidate_{cand_id:03d}.png'\n",
        "    cand_json = pathlib.Path(CONFIG['paths']['candidates']) / f'candidate_{cand_id:03d}.json'\n",
        "\n",
        "    # Make a side-by-side preview\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(8, 4), dpi=120)\n",
        "    ax[0].set_title('optical (demo)')\n",
        "    ax[0].imshow(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))\n",
        "    ax[0].axis('off')\n",
        "    ax[1].set_title(f'edges (score={edge_score})')\n",
        "    ax[1].imshow(edges, cmap='gray')\n",
        "    ax[1].axis('off')\n",
        "    fig.tight_layout()\n",
        "    fig.canvas.draw()\n",
        "    ensure_dir(cand_png.parent)\n",
        "    fig.savefig(str(cand_png), bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Save candidate JSON\n",
        "    cand_rec = {\n",
        "        \"id\": cand_id,\n",
        "        \"score\": edge_score,\n",
        "        \"threshold\": CONFIG['detect']['min_edge_score'],\n",
        "        \"preview\": str(cand_png),\n",
        "        \"source_tile\": str(tile_png),\n",
        "        \"created\": RUN_TS\n",
        "    }\n",
        "    write_json(cand_json, cand_rec)\n",
        "    cand_list.append(cand_rec)\n",
        "else:\n",
        "    print('No candidates: score below threshold.')\n",
        "\n",
        "# Write global candidates list\n",
        "candidates_manifest = {\n",
        "    \"created\": RUN_TS,\n",
        "    \"seed\": SEED,\n",
        "    \"detector\": \"canny_edge_density\",\n",
        "    \"params\": {\"low\": low, \"high\": high, \"min_edge_score\": CONFIG['detect']['min_edge_score']},\n",
        "    \"candidates\": cand_list\n",
        "}\n",
        "write_json(pathlib.Path(CONFIG['paths']['candidates']) / 'candidates.json', candidates_manifest)\n",
        "print(f'Wrote candidates.json with {len(cand_list)} entr(ies).')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Verify (demo) â†’ Simple Gate\n",
        "For the minimal demo we treat the detectorâ€™s threshold as the entire verification step. In a real system, this stage should combine â‰¥2 modalities (e.g., DEM microrelief + vegetation time-series, or SAR + historical text) and produce calibrated uncertainty.\n",
        "\n",
        "We still emit a verification manifest to wire the stage, making it easy to swap in your real logic later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "verified = []\n",
        "for c in cand_list:\n",
        "    c2 = dict(c)\n",
        "    c2[\"verified\"] = True\n",
        "    c2[\"uncertainty_demo\"] = 0.25  # placeholder\n",
        "    verified.append(c2)\n",
        "\n",
        "verify_manifest = {\n",
        "    \"created\": RUN_TS,\n",
        "    \"rule\": \"score>=min_edge_score\",\n",
        "    \"verified\": verified\n",
        "}\n",
        "write_json(pathlib.Path(CONFIG['paths']['candidates']) / 'verify_manifest.json', verify_manifest)\n",
        "print('Wrote verify_manifest.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Dossier â†’ per-candidate bundle\n",
        "Create a simple dossier (.md + .png) for each verified candidate. In the real pipeline this includes maps, overlays, time-series plots, uncertainty panels, and an ethics note/sovereignty banner where applicable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dossiers = []\n",
        "for c in verified:\n",
        "    did = c['id']\n",
        "    md_path = pathlib.Path(CONFIG['paths']['dossiers']) / f'dossier_{did:03d}.md'\n",
        "    png_src = pathlib.Path(c['preview'])\n",
        "    record = {\n",
        "        \"id\": did,\n",
        "        \"figure\": str(png_src),\n",
        "        \"summary\": {\n",
        "            \"score\": c['score'],\n",
        "            \"uncertainty_demo\": c['uncertainty_demo'],\n",
        "            \"source_tile\": c['source_tile']\n",
        "        }\n",
        "    }\n",
        "    md = []\n",
        "    md.append(f\"# Dossier â€” Candidate {did:03d}\\n\")\n",
        "    md.append(f\"- Created: {RUN_TS}\\n\")\n",
        "    md.append(f\"- Source tile: {c['source_tile']}\\n\")\n",
        "    md.append(f\"- Detector score: {c['score']} (min={CONFIG['detect']['min_edge_score']})\\n\")\n",
        "    md.append(f\"- Uncertainty (demo): {c['uncertainty_demo']}\\n\")\n",
        "    md.append(f\"\\n![]({png_src})\\n\")\n",
        "    md.append(\"\\n> NOTE: This is a minimal scaffold dossier. Replace with real maps, DEM hillshades, SAR overlays, NDVI time-series, and sovereignty notices as appropriate.\\n\")\n",
        "    ensure_dir(md_path.parent)\n",
        "    md_path.write_text(\"\".join(md), encoding='utf-8')\n",
        "    dossiers.append({\"id\": did, \"path\": str(md_path)})\n",
        "\n",
        "dossiers_manifest = {\n",
        "    \"created\": RUN_TS,\n",
        "    \"count\": len(dossiers),\n",
        "    \"items\": dossiers\n",
        "}\n",
        "write_json(pathlib.Path(CONFIG['paths']['dossiers']) / 'dossiers_manifest.json', dossiers_manifest)\n",
        "print(f\"Wrote dossiers_manifest.json with {len(dossiers)} entr(ies).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Final Recap â†’ Manifests & File Tree\n",
        "We summarize run metadata and print a limited file tree so you can quickly confirm artifacts exist. Use the Kaggle sidebar or the output browser to download your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_manifest = {\n",
        "    \"run\": CONFIG['run'],\n",
        "    \"aoi\": CONFIG['aoi'],\n",
        "    \"tiling\": CONFIG['tiling'],\n",
        "    \"detect\": CONFIG['detect'],\n",
        "    \"paths\": CONFIG['paths'],\n",
        "    \"artifacts\": {\n",
        "        \"candidates_json\": str(pathlib.Path(CONFIG['paths']['candidates']) / 'candidates.json'),\n",
        "        \"verify_manifest\": str(pathlib.Path(CONFIG['paths']['candidates']) / 'verify_manifest.json'),\n",
        "        \"dossiers_manifest\": str(pathlib.Path(CONFIG['paths']['dossiers']) / 'dossiers_manifest.json')\n",
        "    }\n",
        "}\n",
        "write_json(ART_ROOT / 'run_manifest.json', final_manifest)\n",
        "print('Saved artifacts/run_manifest.json')\n",
        "\n",
        "print('\\n# artifacts/')\n",
        "for p in limited_tree(ART_ROOT, max_files=200):\n",
        "    print(' -', p)\n",
        "\n",
        "print('\\n# data/')\n",
        "for p in limited_tree(DATA_ROOT, max_files=200):\n",
        "    print(' -', p)\n",
        "\n",
        "print('\\nDone.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps (Swap in your real pipeline)\n",
        "1. Data Fetchers â†’ Replace the synthetic tile with real data loaders (Sentinel/Landsat/SRTM/NICFI). Keep small AOIs for Kaggle limits.\n",
        "2. Preprocess â†’ Tile/reproject/normalize stacks; compute DEM hillshades & local relief; clip to AOI.\n",
        "3. Detect â†’ Add your CV/VLM/DEM detection: edges+Hough, CLIP similarity, UNet segmentation, random forest on environmental layers, etc.\n",
        "4. Verify â†’ Enforce multi-proof rules (e.g., DEM microrelief + vegetation seasonal anomaly), causal plausibility graph, and calibrated uncertainty.\n",
        "5. Dossier â†’ Render maps/overlays/plots (NDVI time-series, SAR backscatter, DEM), add sovereignty notes (CARE) when applicable.\n",
        "6. Configs â†’ Keep all knobs in configs/*.yaml; pin seeds and dataset versions for reproducibility; wire to your CLI.\n",
        "7. CI â†’ If running in your repo via Actions, run lint/tests/repro checks on each PR; for Kaggle, prefer pinned images + Save & Run All."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
