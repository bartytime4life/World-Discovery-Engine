# Re-run creation after state reset
import json, datetime
from pathlib import Path

nb = {
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
   "kernelspec": {"name": "python3", "display_name": "Python 3"},
   "language_info": {"name": "python", "version": "3.x"},
 },
 "cells": [
  {"cell_type":"markdown","metadata":{},"source":[
    "# ðŸŒ World Discovery Engine (WDE) â€” Kaggle Starter\n",
    "\n",
    "Minimal, reproducible starter: prints env info, lists `/kaggle/input`, reads a config if present, and writes a demo candidates CSV + manifest.\n"
  ]},
  {"cell_type":"code","metadata":{},"source":[
    "import os, sys, platform, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "INPUT_DIR = Path('/kaggle/input')\n",
    "WORK_DIR = Path('/kaggle/working') if Path('/kaggle/working').exists() else Path('.')\n",
    "OUT_DIR = WORK_DIR / 'wde_outputs'\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Python:', sys.version.split()[0])\n",
    "print('Platform:', platform.platform())\n",
    "print('INPUT_DIR exists:', INPUT_DIR.exists())\n",
    "print('WORK_DIR:', WORK_DIR)\n",
    "print('OUT_DIR:', OUT_DIR)\n"
  ]},
  {"cell_type":"markdown","metadata":{},"source":["## 1) Inspect inputs"]},
  {"cell_type":"code","metadata":{},"source":[
    "def list_tree(root, max_depth=2, max_files=10):\n",
    "    root = Path(root)\n",
    "    if not root.exists():\n",
    "        print('No input directory found.')\n",
    "        return\n",
    "    base_depth = len(root.parts)\n",
    "    for p, dnames, fnames in os.walk(root):\n",
    "        depth = len(Path(p).parts) - base_depth\n",
    "        if depth > max_depth:\n",
    "            dnames[:] = []\n",
    "            continue\n",
    "        print(str(Path(p)), f'(dirs={len(dnames)} files={len(fnames)})')\n",
    "        for fn in fnames[:max_files]:\n",
    "            print('  -', fn)\n",
    "        if len(fnames) > max_files:\n",
    "            print('  ...')\n",
    "list_tree('/kaggle/input')\n"
  ]},
  {"cell_type":"markdown","metadata":{},"source":["## 2) Load config (configs/kaggle.yaml if available)"]},
  {"cell_type":"code","metadata":{},"source":[
    "CFG_PATH = Path('./configs/kaggle.yaml')\n",
    "CFG = {}\n",
    "if CFG_PATH.exists():\n",
    "    try:\n",
    "        import yaml\n",
    "        with CFG_PATH.open('r', encoding='utf-8') as f:\n",
    "            CFG = yaml.safe_load(f)\n",
    "    except Exception as e:\n",
    "        print('Config parse error, using default:', e)\n",
    "        CFG = {}\n",
    "else:\n",
    "    CFG = {'random_seed': 42, 'sample_rows': 1000, 'outputs_dir': 'wde_outputs'}\n",
    "print('Config:', json.dumps(CFG, indent=2))\n"
  ]},
  {"cell_type":"markdown","metadata":{},"source":["## 3) Generate a tiny demo candidates CSV"]},
  {"cell_type":"code","metadata":{},"source":[
    "import csv, random\n",
    "random.seed(CFG.get('random_seed', 42))\n",
    "N = 50\n",
    "lat_min, lat_max = -15.0, -2.0\n",
    "lon_min, lon_max = -75.0, -45.0\n",
    "rows = []\n",
    "for i in range(N):\n",
    "    lat = random.uniform(lat_min, lat_max)\n",
    "    lon = random.uniform(lon_min, lon_max)\n",
    "    rows.append({'id': f'cand_{i+1}','lat': round(lat, 6),'lon': round(lon, 6),'score': round(random.random(),4),'confidence': round(0.6 + 0.4*random.random(), 3),'notes': 'demo'})\n",
    "cand_path = OUT_DIR / 'demo_candidates_top50.csv'\n",
    "with cand_path.open('w', newline='', encoding='utf-8') as f:\n",
    "    w = csv.DictWriter(f, fieldnames=['id','lat','lon','score','confidence','notes'])\n",
    "    w.writeheader()\n",
    "    for r in rows: w.writerow(r)\n",
    "print('Saved:', cand_path)\n"
  ]},
  {"cell_type":"markdown","metadata":{},"source":["## 4) Save a run manifest"]},
  {"cell_type":"code","metadata":{},"source":[
    "artifacts = []\n",
    "for p in OUT_DIR.rglob('*'):\n",
    "    if p.is_file(): artifacts.append({'path': str(p.relative_to(OUT_DIR)), 'size_bytes': p.stat().st_size})\n",
    "manifest = {'generated': datetime.utcnow().isoformat()+'Z', 'outputs_dir': str(OUT_DIR), 'artifacts': artifacts}\n",
    "with (OUT_DIR / 'run_manifest.json').open('w', encoding='utf-8') as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "print('Manifest entries:', len(artifacts))\n"
  ]},
  {"cell_type":"markdown","metadata":{},"source":[
    "## 5) Next steps\n",
    "- Attach real datasets and expand to the full pipeline (`WDE_End_to_End.ipynb` or `ade_discovery_pipeline.ipynb`).\n",
    "- Use `tools/wde_export.py` to make `submission.csv`, a manifest, and a zipped bundle.\n"
  ]}
 ]
}

nb_path = Path('/mnt/data/notebooks')
nb_path.mkdir(parents=True, exist_ok=True)
out_nb = nb_path / 'WDE_Kaggle_Starter.ipynb'
with out_nb.open('w', encoding='utf-8') as f:
    json.dump(nb, f, indent=2)
str(out_nb)
