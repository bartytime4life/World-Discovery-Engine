# .github/workflows/kaggle_notebook_check.yml
# ==============================================================================
# WDE — Kaggle Notebook Check (Ultimate)
# Purpose: Validate that ade_discovery_pipeline.ipynb runs end-to-end in a
# Kaggle-like environment, is reproducible, and emits expected artifacts.
# Key Features:
# - Runs on PRs that touch the notebook, world_engine/, or configs/
# - Matches Kaggle kernels (Python 3.10/3.11 matrix, pip cache)
# - Optional parameterized execution via papermill (fast mode, offline mode)
# - Lints metadata (nbstripout) and strips outputs drift
# - Verifies outputs (dossiers, JSON/GeoJSON logs), coordinates redaction guard
# - Uploads artifacts and posts a sticky PR summary comment
# ==============================================================================

name: Kaggle Notebook Check

on:
  pull_request:
    branches: ["**"]
    paths:
      - "notebooks/ade_discovery_pipeline.ipynb"
      - "notebooks/**/*.ipynb"
      - "world_engine/**"
      - "configs/**"
      - ".github/workflows/kaggle_notebook_check.yml"
  workflow_dispatch:
    inputs:
      execute:
        description: "Execute notebook?"
        type: choice
        options: ["true","false"]
        default: "true"
        required: true
      offline_mode:
        description: "Force offline/sample-data mode (avoid external downloads)?"
        type: choice
        options: ["true","false"]
        default: "true"
        required: true
      fast_mode:
        description: "Notebook fast path (smaller AOI, fewer tiles)?"
        type: choice
        options: ["true","false"]
        default: "true"
        required: true
      seed:
        description: "Random seed for reproducibility"
        type: number
        default: 42
        required: true
      timeout:
        description: "Execution timeout per notebook (seconds)"
        type: number
        default: 1800
        required: true

concurrency:
  group: nbcheck-${{ github.ref }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: false

permissions:
  contents: read
  actions: read
  checks: read
  statuses: write
  pull-requests: write

env:
  NB_PATH: notebooks/ade_discovery_pipeline.ipynb
  OUT_NB_PATH: notebooks/ade_discovery_pipeline_out.ipynb
  PY_VERSIONS: '["3.10","3.11"]'
  DEFAULT_EXECUTE: "true"
  DEFAULT_OFFLINE: "true"
  DEFAULT_FAST: "true"
  DEFAULT_TIMEOUT: "1800"
  DEFAULT_SEED: "42"
  # Redaction guard: block high-precision coords leaking in artifacts
  COORD_REGEX: '[+-]?[0-9]{1,3}\.[0-9]{6,}'

jobs:
  discover:
    name: Discover Notebook
    runs-on: ubuntu-latest
    outputs:
      nb_exists: ${{ steps.probe.outputs.nb_exists }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Probe notebook presence
        id: probe
        run: |
          if [ -f "${{ env.NB_PATH }}" ]; then
            echo "nb_exists=true" >> "$GITHUB_OUTPUT"
          else
            echo "nb_exists=false" >> "$GITHUB_OUTPUT"
          fi

  notebook-check:
    name: Notebook Check (Python ${{ matrix.python }})
    needs: discover
    if: needs.discover.outputs.nb_exists == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 60
    strategy:
      fail-fast: false
      matrix:
        python: ${{ fromJson(env.PY_VERSIONS) }}

    steps:
      # ------------------------------------------------------------
      # 1. Checkout repository
      # ------------------------------------------------------------
      - name: Checkout repository
        uses: actions/checkout@v4

      # ------------------------------------------------------------
      # 2. Setup Python (match Kaggle kernels: 3.10/3.11)
      # ------------------------------------------------------------
      - name: Setup Python ${{ matrix.python }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}
          cache: 'pip'

      # ------------------------------------------------------------
      # 3. Install dependencies (align with Kaggle runtime + notebook tools)
      # ------------------------------------------------------------
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Project deps
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          # Tools for execution and conversion
          pip install nbconvert nbclient papermill jupyter nbformat jupyterlab_pygments pygments
          # Lint/strip helpers
          pip install nbstripout

      # ------------------------------------------------------------
      # 4. Lint notebook JSON metadata (no large embedded outputs in VCS)
      # ------------------------------------------------------------
      - name: Lint notebook metadata (nbstripout check)
        run: |
          nbstripout --check "${{ env.NB_PATH }}"

      # ------------------------------------------------------------
      # 5. Execute notebook end-to-end (papermill) with parameters
      #     - Respect workflow_dispatch inputs or env defaults
      #     - Force fast/offline path for CI (avoid external I/O)
      # ------------------------------------------------------------
      - name: Normalize config
        id: cfg
        run: |
          ex="${{ github.event_name == 'workflow_dispatch' && inputs.execute || env.DEFAULT_EXECUTE }}"
          off="${{ github.event_name == 'workflow_dispatch' && inputs.offline_mode || env.DEFAULT_OFFLINE }}"
          fast="${{ github.event_name == 'workflow_dispatch' && inputs.fast_mode || env.DEFAULT_FAST }}"
          to="${{ github.event_name == 'workflow_dispatch' && inputs.timeout || env.DEFAULT_TIMEOUT }}"
          seed="${{ github.event_name == 'workflow_dispatch' && inputs.seed || env.DEFAULT_SEED }}"
          echo "execute=$ex"   >> "$GITHUB_OUTPUT"
          echo "offline=$off"  >> "$GITHUB_OUTPUT"
          echo "fast=$fast"    >> "$GITHUB_OUTPUT"
          echo "timeout=$to"   >> "$GITHUB_OUTPUT"
          echo "seed=$seed"    >> "$GITHUB_OUTPUT"

      - name: Run notebook with papermill
        if: steps.cfg.outputs.execute == 'true'
        run: |
          # Parameters expected by the notebook (adjust to your nb):
          # fast_mode: bool, offline_mode: bool, seed: int, out_dir: str
          papermill "${{ env.NB_PATH }}" "${{ env.OUT_NB_PATH }}" \
            -k python3 \
            -p fast_mode  ${{ steps.cfg.outputs.fast }} \
            -p offline_mode  ${{ steps.cfg.outputs.offline }} \
            -p seed ${{ steps.cfg.outputs.seed }} \
            -p out_dir "outputs" \
            --execution-timeout ${{ steps.cfg.outputs.timeout }}

      - name: Convert to HTML (always)
        run: |
          mkdir -p artifacts/html
          SRC="${{ env.OUT_NB_PATH }}"
          if [ ! -f "$SRC" ]; then SRC="${{ env.NB_PATH }}"; fi
          jupyter nbconvert --to html --output-dir artifacts/html "$SRC"

      # ------------------------------------------------------------
      # 6. Verify outputs (candidate dossiers, GeoJSON, JSON logs)
      # ------------------------------------------------------------
      - name: Verify expected outputs
        run: |
          set -euo pipefail
          test -d outputs || (echo "❌ outputs/ directory missing" && exit 1)
          echo "✅ outputs/ present"
          # Examples — customize to your pipeline’s expected files:
          if [ -f outputs/candidates.json ]; then
            echo "✅ candidates.json present"
          else
            echo "⚠️ candidates.json not found — checking alternate names"
            ls -la outputs || true
          fi
          # At least one dossier/summary
          if ls outputs/*dossier*.* >/dev/null 2>&1 || ls outputs/*report*.* >/dev/null 2>&1; then
            echo "✅ dossier/report artifacts present"
          else
            echo "⚠️ dossier/report artifacts not found — check notebook output path"
          fi

      # ------------------------------------------------------------
      # 7. Coordinates redaction guard (no high-precision coordinates in logs/artifacts)
      # ------------------------------------------------------------
      - name: Redaction guard (coordinates)
        shell: bash
        run: |
          set -euo pipefail
          shopt -s nullglob globstar
          if grep -RIEn "${{ env.COORD_REGEX }}" outputs || true; then
            echo "High-precision coordinates detected in outputs. Please round/redact before committing." >&2
            exit 1
          fi

      # ------------------------------------------------------------
      # 8. Upload artifacts (executed notebook, HTML, outputs)
      # ------------------------------------------------------------
      - name: Upload notebook & outputs
        uses: actions/upload-artifact@v4
        with:
          name: ade-discovery-pipeline-run-py${{ matrix.python }}
          path: |
            ${{ env.OUT_NB_PATH }}
            artifacts/html
            outputs/
          retention-days: 14
          if-no-files-found: warn

      # ------------------------------------------------------------
      # 9. Post sticky summary comment on PR
      # ------------------------------------------------------------
      - name: PR Summary Comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const header = `### Kaggle Notebook Check (Python ${{ matrix.python }})`;
            const ok = core.summary._buffer.length === 0 ? true : true; // placeholder; we already failed earlier if something broke
            const body = `${header}

- Execute: **${{ steps.cfg.outputs.execute }}**
- Fast mode: **${{ steps.cfg.outputs.fast }}**
- Offline: **${{ steps.cfg.outputs.offline }}**
- Timeout (s): **${{ steps.cfg.outputs.timeout }}**

Artifacts:
- Notebook & HTML: \`ade-discovery-pipeline-run-py${{ matrix.python }}\`
- Outputs directory uploaded

_If this check failed, see logs above for the failing step._`;

            const prNumber = context.payload.pull_request.number;
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber
            });
            const tag = "### Kaggle Notebook Check (Python ";
            const bot = comments.find(c => c.user.type === 'Bot' && c.body && c.body.includes(tag));
            if (bot) {
              await github.rest.issues.updateComment({ owner: context.repo.owner, repo: context.repo.repo, comment_id: bot.id, body });
            } else {
              await github.rest.issues.createComment({ owner: context.repo.owner, repo: context.repo.repo, issue_number: prNumber, body });
            }

  # Optional: quick no-op if notebook missing (keeps checks green with explicit message)
  skip:
    name: Skip (No Notebook)
    runs-on: ubuntu-latest
    needs: discover
    if: needs.discover.outputs.nb_exists != 'true'
    steps:
      - run: echo "No ade_discovery_pipeline.ipynb present — skipping Kaggle Notebook Check."