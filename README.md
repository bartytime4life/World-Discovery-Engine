# ğŸŒ World Discovery Engine (WDE)

**OpenAI â†’ Z Challenge Â· Archaeology & Earth Systems**
*Reproducible AI pipeline for archaeologically significant discovery in Amazonia and beyond*

---

## ğŸ“Œ Overview

The **World Discovery Engine (WDE)** is a multi-modal AI pipeline that surfaces candidate archaeological sites (e.g. Anthropogenic Dark Earths (ADEs), earthworks, geoglyphs) from open geospatial data and historical archives.

It is designed to:

* **Run on Kaggle** as a single notebook (`notebooks/ade_discovery_pipeline.ipynb`).
* **Fuse heterogeneous sources** â€” Sentinel imagery, SAR, LiDAR, DEM, soils, vegetation, hydrology, colonial diaries, and user-uploaded maps/photos.
* **Validate discoveries** with â‰¥2 proofs: NDVI/EVI fingerprints, geomorphology, causal plausibility graphs, uncertainty estimates.
* **Generate candidate site dossiers** â€” maps, overlays, causal graphs, ADE fingerprints, refutation tests.
* **Respect ethics & sovereignty** (CARE Principles, FPIC, IPHAN law).
* **Be reproducible & auditable** â€” versioned configs, CI, Docker, DVC/Kaggle dataset tracking.

---

## âš™ï¸ Repository Structure

```text
â”œâ”€â”€ README.md              # Project intro (this file)
â”œâ”€â”€ LICENSE                # Open license (code), CC-0 (notebooks)
â”œâ”€â”€ requirements.txt       # Python dependencies (pinned for reproducibility)
â”œâ”€â”€ Dockerfile             # Containerized runtime (GDAL/PDAL, PyTorch, etc.)
â”œâ”€â”€ .github/workflows/     # CI/CD pipelines (lint, tests, Kaggle notebook CI)
â”‚   â”œâ”€â”€ kaggle_notebook_check.yml
â”‚   â”œâ”€â”€ kaggle_notebook_ci.yml
â”‚   â””â”€â”€ lint.yml
â”œâ”€â”€ world_engine/          # Core pipeline package
â”‚   â”œâ”€â”€ ingest.py          # Step 1 â€“ tiling & ingestion
â”‚   â”œâ”€â”€ detect.py          # Step 2 â€“ coarse anomaly scan
â”‚   â”œâ”€â”€ evaluate.py        # Step 3 â€“ mid-scale evaluation
â”‚   â”œâ”€â”€ verify.py          # Step 4 â€“ verification & fusion
â”‚   â”œâ”€â”€ report.py          # Step 5 â€“ dossier generation
â”‚   â””â”€â”€ utils/, models/    # Shared functions & ML models
â”œâ”€â”€ configs/               # Config files (YAML/JSON for AOIs, datasets, models)
â”œâ”€â”€ data/                  # (DVC/Kaggle-linked) raw, interim, output artifacts
â”œâ”€â”€ notebooks/             # Kaggle notebook(s), exploration, experiments
â”‚   â””â”€â”€ ade_discovery_pipeline.ipynb
â”œâ”€â”€ tests/                 # Unit & integration tests
â””â”€â”€ docs/                  # Architecture, ethics, datasets, usage guides
```

See full structure in \[docs/repository\_structure.md].

---

## ğŸš€ Quickstart

### 1. Kaggle Notebook

Run the pipeline end-to-end on Kaggle:

```bash
# In Kaggle Notebook terminal
!pip install -r requirements.txt
!papermill notebooks/ade_discovery_pipeline.ipynb notebooks/out.ipynb -k python3
```

Outputs will be in `/kaggle/working/outputs/`, including:

* `candidates.json`, `candidates.geojson`
* `reports/` (PDF/HTML dossiers)
* `pag/` (causal graphs)
* `uncertainty/` (histograms, JSON)
* `ssim/` (counterfactual what-if tests)

### 2. CLI (local use)

```bash
# Install
pip install -e .
# Run pipeline
wde full-run --config configs/default.yaml
# Or stepwise
wde ingest --aoi data/aoi/brazil.geojson
wde scan
wde evaluate
wde verify
wde report
```

---

## ğŸ” Pipeline (Discovery Funnel)

1. **Ingestion** â€” Tile AOI (0.05Â°), load Sentinel-2, Sentinel-1, DEM, SoilGrids, MapBiomas, HydroSHEDS, GEDI, + user overlays.
2. **Coarse Scan** â€” CV filters (edges, Hough), texture (LBP/GLCM), DEM hillshades, VLM captioning.
3. **Mid-Scale Evaluation** â€” LiDAR canopy removal, NDVI/EVI time-series, hydro-geomorph plausibility, historical concordance.
4. **Verification** â€” Multi-proof rule, ADE fingerprints (seasonal NDVI, flora, geomorph), PAG causal graphs, Bayesian GNN uncertainty, SSIM what-if tests.
5. **Reporting** â€” Candidate dossiers: maps, NDVI plots, SAR, historical snippets, causal graphs, uncertainty histograms, SSIM overlays, ADE checklist, confidence narratives.

---

## ğŸ“Š Data Sources

All datasets are open, CC-0/CC-BY, reproducible via Kaggle or APIs:

* **Satellite**: Sentinel-2 (optical), Sentinel-1 (SAR), Landsat, NICFI Planet mosaics.
* **Elevation & LiDAR**: SRTM, Copernicus DEM, GEDI, OpenTopography.
* **Soils**: ISRIC SoilGrids, SISLAC, RADAMBRASIL legacy.
* **Vegetation & Land Cover**: MapBiomas, MODIS NDVI/EVI, floristic indicators.
* **Hydrology**: HydroSHEDS (rivers, basins, floodplains).
* **Historical**: Colonial maps, missionary diaries (OCR+NLP), archaeological site DBs.
* **User Overlays**: Uploaded docs/maps/images, auto-OCR + georeference.

See full \[docs/datasets.md] registry.

---

## ğŸ§­ Ethics & Governance

* **CARE Principles** (Collective Benefit, Authority to Control, Responsibility, Ethics).
* **FPIC & IPHAN compliance** for Brazil â€” mandatory archaeological authorization.
* **Ethics-by-Design** â€” auto-flags Indigenous lands, sovereignty notices in outputs.
* **Data colonialism safeguards** â€” discoveries are not auto-published; outputs intended for expert review & local collaboration.

See \[docs/ETHICS.md] for full governance.

---

## ğŸ”¬ Reproducibility

* **CausalOps lifecycle** â€” Arrange â†’ Create â†’ Validate â†’ Test â†’ Publish â†’ Operate â†’ Monitor â†’ Document.
* **Deterministic runs** â€” fixed seeds, logged configs, Docker reproducibility.
* **CI/CD** â€” GitHub Actions run lint, unit/integration tests, Kaggle notebook validation.
* **Artifacts** â€” All intermediate outputs logged: anomaly scores, PAG graphs, refutation reports.

---

## ğŸ“‘ References

* Architecture & pipeline spec
* Enrichment datasets & anomaly detection methods
* Repository structure
* ADE discovery pipeline (Kaggle notebook)
* Data connection guide
* Core sampling databases

---
